<launch>

  <arg name="gpu" default="-1" />
  <arg name="INPUT_IMAGE" default="/rs_l515/color/image_raw" />
  <arg name="INPUT_DEPTH_IMAGE" default="/rs_l515/depth/image_rect_raw" />
  <arg name="INPUT_CAMERA_INFO" default="/rs_l515/color/camera_info" />
  <arg name="LIMB_PART" default="RHand" />

  

  <node name="people_pose_estimation_2d"
        pkg="jsk_perception" type="people_pose_estimation_2d.py"
        output="screen">
    <remap from="~input" to="$(arg INPUT_IMAGE)" />
    <remap from="~input/info" to="$(arg INPUT_CAMERA_INFO)" />
    <remap from="~input/depth" to="$(arg INPUT_DEPTH_IMAGE)" />
    <rosparam subst_value="true">
      gpu: $(arg gpu)
      model_file: $(find jsk_perception)/trained_data/pose_estimation_2d_chainermodel.pkl
      hand:
        enable: true
        model_file: $(find jsk_perception)/trained_data/pose_estimation_2d_hand.chainermodel
      with_depth: false
      scales: [0.38]
      stride: 8
    </rosparam>
  </node>

  <node name="people_mask_publisher"
        pkg="jsk_perception" type="people_mask_publisher.py"
        output="screen">
    <remap from="~input" to="$(arg INPUT_IMAGE)" />
    <remap from="~input/pose" to="people_pose_estimation_2d/pose_2d" />
    <rosparam subst_value="true">
      queue_size: 50
      person_indices: 0
      limb_part: $(arg LIMB_PART)
    </rosparam>
  </node>

  <node name="people_poses_to_poses"
        pkg="jsk_recognition_msgs" type="people_pose_array_to_pose_array.py">
    <remap from="~input" to="people_pose_estimation_2d/pose" />
  </node>

 

</launch>
